{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se carga el dataset que se utilizara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of          0\n",
      "0      6.0\n",
      "1      7.1\n",
      "2     10.0\n",
      "3      6.9\n",
      "4      8.4\n",
      "5      8.9\n",
      "6      6.7\n",
      "7      7.6\n",
      "8      3.9\n",
      "9      4.9\n",
      "10     3.6\n",
      "11     3.4\n",
      "12     2.7\n",
      "13     2.2\n",
      "14     3.0\n",
      "15     2.6\n",
      "16     3.0\n",
      "17     2.7\n",
      "18     4.0\n",
      "19     3.8\n",
      "20     3.9\n",
      "21     5.8\n",
      "22     7.2\n",
      "23     6.8\n",
      "24     5.9\n",
      "25     6.4\n",
      "26     6.7\n",
      "27     7.6\n",
      "28     6.9\n",
      "29     4.8\n",
      "...    ...\n",
      "4212   3.4\n",
      "4213   4.2\n",
      "4214   4.8\n",
      "4215   2.3\n",
      "4216   3.0\n",
      "4217   2.7\n",
      "4218   3.0\n",
      "4219   2.6\n",
      "4220   2.5\n",
      "4221   3.3\n",
      "4222   7.7\n",
      "4223   9.7\n",
      "4224  12.7\n",
      "4225  13.2\n",
      "4226  12.7\n",
      "4227  15.8\n",
      "4228  13.6\n",
      "4229   9.1\n",
      "4230   5.3\n",
      "4231   2.8\n",
      "4232   5.0\n",
      "4233   4.5\n",
      "4234   3.3\n",
      "4235   3.4\n",
      "4236   3.4\n",
      "4237   2.8\n",
      "4238   2.5\n",
      "4239   2.4\n",
      "4240   2.9\n",
      "4241   2.8\n",
      "\n",
      "[4242 rows x 1 columns]>\n"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "dataset =  DataFrame(pd.read_csv('windserie.csv', header=None))\n",
    "print(dataset.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplica media movil en los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 5760x1920 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "dataset_soft = dataset.rolling(window=2, min_periods=1).mean()\n",
    "\n",
    "pyplot.figure(num=None, figsize=(18, 6), dpi=320, facecolor='w', edgecolor='k')\n",
    "pyplot.style.use(\"ggplot\")\n",
    "pyplot.plot(dataset[1:150], label='Input')\n",
    "pyplot.plot(dataset_soft[1:150], label='Soft')\n",
    "pyplot.title('Media móvil Aplicada')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el tamaño de imagen que se utilizara (en pixeles). Y se preparan datos para su conversión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2810, 32, 32, 1) (1368, 32, 32, 1) (2810, 1) (1368, 1)\n"
     ]
    }
   ],
   "source": [
    "import Tools as tls\n",
    "import numpy as np\n",
    "\n",
    "IMAGE_SIZE=32\n",
    "X_train, y_train, X_test, y_test = tls.SerieToImage(dataset_soft, IMAGE_SIZE)\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1],X_train.shape[2], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1],X_test.shape[2], 1))\n",
    "y_train = y_train.reshape((y_train.shape[0], y_train.shape[1]))\n",
    "y_test = y_test.reshape((y_test.shape[0], y_test.shape[1]))\n",
    "\n",
    "print (X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se envian matrices de datos de series de tiempo para generar las imagenes en formato jepg. Se guardan en el directiorio definido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from matplotlib import image\n",
    "\n",
    "tls.imageDataToJPG(X_train, y_train, 'images/train')\n",
    "tls.imageDataToJPG(X_test, y_test, 'images/test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se muestra ejemplo imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo serie de tiempo como imagen\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Ejemplo serie de tiempo como imagen')\n",
    "img = image.imread('images/train/13.jpeg')\n",
    "pyplot.figure()\n",
    "pyplot.imshow(img)\n",
    "pyplot.colorbar()\n",
    "pyplot.grid(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se construye modelo y se compila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Convolution2D, Dense, MaxPooling2D, Flatten, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "filt = 32\n",
    "kernel = 3\n",
    "dropout = 0.05\n",
    "in_shape = (IMAGE_SIZE,IMAGE_SIZE,1)\n",
    "\n",
    "model = Sequential((\n",
    "            Convolution2D(filters=filt,kernel_size=kernel, activation='relu',input_shape=in_shape),\n",
    "            MaxPooling2D(pool_size=(3, 3)),\n",
    "            Convolution2D(filters=filt,kernel_size=kernel, activation='relu'),\n",
    "            MaxPooling2D(pool_size=(3, 3)),\n",
    "            Flatten(),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(0.05),\n",
    "            Dense(1,activation='linear'),\n",
    "            ))     \n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se entrena modelo y se guarda historia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2810 samples, validate on 1368 samples\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv2d_3/convolution}} = Conv2D[T=DT_FLOAT, _class=[\"loc:@training_1/Adam/gradients/conv2d_3/convolution_grad/Conv2DBackpropFilter\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_1/Adam/gradients/conv2d_3/convolution_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer, conv2d_3/kernel/read)]]\n\t [[{{node loss_1/mul/_225}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_636_loss_1/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-54a23383cef4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[{{node conv2d_3/convolution}} = Conv2D[T=DT_FLOAT, _class=[\"loc:@training_1/Adam/gradients/conv2d_3/convolution_grad/Conv2DBackpropFilter\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_1/Adam/gradients/conv2d_3/convolution_grad/Conv2DBackpropFilter-0-TransposeNHWCToNCHW-LayoutOptimizer, conv2d_3/kernel/read)]]\n\t [[{{node loss_1/mul/_225}} = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_636_loss_1/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=24, validation_data=(X_test, y_test), verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se grafican MSE y MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyplot.style.use(\"ggplot\")\n",
    "pyplot.figure()\n",
    "N = epochs\n",
    "pyplot.figure(num=None, figsize=(8, 6), dpi=320, facecolor='w', edgecolor='k')\n",
    "pyplot.plot(np.arange(0, N), history.history[\"mean_squared_error\"], label=\"mse\")\n",
    "pyplot.plot(np.arange(0, N), history.history[\"val_mean_squared_error\"], label=\"val_mse\")\n",
    "pyplot.title(\"Training MSE\")\n",
    "pyplot.xlabel(\"Epoch #\")\n",
    "pyplot.ylabel(\"MSE\")\n",
    "pyplot.legend(loc=\"upper right\")\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realizan predicciones con datos de prueba y se grafican"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se realizan predicciones con datos de prueba\n",
    "predictions = model.predict(X_test, 24, verbose=2)\n",
    "    \n",
    "#Se grafican predicciones\n",
    "pyplot.figure(num=None, figsize=(18, 6), dpi=320, facecolor='w', edgecolor='k')\n",
    "pyplot.plot(y_test[1:100,], label='Real')\n",
    "pyplot.plot(predictions[1:100,], label='Predicción')\n",
    "pyplot.title('Valor predicción contra real')\n",
    "pyplot.xlabel('Epochs')\n",
    "pyplot.ylabel('Value')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
