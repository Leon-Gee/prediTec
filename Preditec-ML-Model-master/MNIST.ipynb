{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.datasets import mnist\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 1000\n",
    "\n",
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "og_test = x_test\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(x_train[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.2948 - acc: 0.9100 - val_loss: 0.0633 - val_acc: 0.9798\n",
      "Epoch 2/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0946 - acc: 0.9714 - val_loss: 0.0422 - val_acc: 0.9859\n",
      "Epoch 3/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0724 - acc: 0.9783 - val_loss: 0.0373 - val_acc: 0.9877\n",
      "Epoch 4/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0596 - acc: 0.9821 - val_loss: 0.0350 - val_acc: 0.9873\n",
      "Epoch 5/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0505 - acc: 0.9853 - val_loss: 0.0326 - val_acc: 0.98970.05 - ETA: 0s - loss: 0.0504 - acc:\n",
      "Epoch 6/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0434 - acc: 0.9869 - val_loss: 0.0307 - val_acc: 0.9890\n",
      "Epoch 7/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0391 - acc: 0.9884 - val_loss: 0.0275 - val_acc: 0.9912\n",
      "Epoch 8/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0353 - acc: 0.9889 - val_loss: 0.0305 - val_acc: 0.9912\n",
      "Epoch 9/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0336 - acc: 0.9896 - val_loss: 0.0286 - val_acc: 0.9912\n",
      "Epoch 10/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0304 - acc: 0.9906 - val_loss: 0.0263 - val_acc: 0.9919\n",
      "Epoch 11/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0296 - acc: 0.9906 - val_loss: 0.0287 - val_acc: 0.9908\n",
      "Epoch 12/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0275 - acc: 0.9913 - val_loss: 0.0272 - val_acc: 0.9913\n",
      "Epoch 13/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0275 - acc: 0.9915 - val_loss: 0.0290 - val_acc: 0.9916\n",
      "Epoch 14/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0275 - acc: 0.9915 - val_loss: 0.0262 - val_acc: 0.9926\n",
      "Epoch 15/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0248 - acc: 0.9924 - val_loss: 0.0260 - val_acc: 0.9916\n",
      "Epoch 16/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0239 - acc: 0.9927 - val_loss: 0.0267 - val_acc: 0.9916\n",
      "Epoch 17/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0229 - acc: 0.9931 - val_loss: 0.0320 - val_acc: 0.9904\n",
      "Epoch 18/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0227 - acc: 0.9929 - val_loss: 0.0298 - val_acc: 0.9928\n",
      "Epoch 19/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0227 - acc: 0.9930 - val_loss: 0.0319 - val_acc: 0.9900\n",
      "Epoch 20/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0218 - acc: 0.9930 - val_loss: 0.0270 - val_acc: 0.9923\n",
      "Epoch 21/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0197 - acc: 0.9939 - val_loss: 0.0291 - val_acc: 0.9920\n",
      "Epoch 22/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0208 - acc: 0.9936 - val_loss: 0.0270 - val_acc: 0.9928\n",
      "Epoch 23/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0196 - acc: 0.9938 - val_loss: 0.0259 - val_acc: 0.9927\n",
      "Epoch 24/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0192 - acc: 0.9938 - val_loss: 0.0327 - val_acc: 0.9920\n",
      "Epoch 25/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0197 - acc: 0.9935 - val_loss: 0.0286 - val_acc: 0.9919\n",
      "Epoch 26/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0189 - acc: 0.9941 - val_loss: 0.0264 - val_acc: 0.9925\n",
      "Epoch 27/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0165 - acc: 0.9951 - val_loss: 0.0271 - val_acc: 0.9923\n",
      "Epoch 28/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0183 - acc: 0.9942 - val_loss: 0.0286 - val_acc: 0.9928\n",
      "Epoch 29/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0169 - acc: 0.9942 - val_loss: 0.0274 - val_acc: 0.9926\n",
      "Epoch 30/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0161 - acc: 0.9948 - val_loss: 0.0262 - val_acc: 0.9924\n",
      "Epoch 31/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0171 - acc: 0.9946 - val_loss: 0.0287 - val_acc: 0.9929\n",
      "Epoch 32/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0178 - acc: 0.9943 - val_loss: 0.0256 - val_acc: 0.9926\n",
      "Epoch 33/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0174 - acc: 0.9945 - val_loss: 0.0296 - val_acc: 0.9926\n",
      "Epoch 34/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0175 - acc: 0.9944 - val_loss: 0.0282 - val_acc: 0.9932\n",
      "Epoch 35/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0151 - acc: 0.9951 - val_loss: 0.0269 - val_acc: 0.9929\n",
      "Epoch 36/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0154 - acc: 0.9949 - val_loss: 0.0289 - val_acc: 0.9932\n",
      "Epoch 37/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0150 - acc: 0.9953 - val_loss: 0.0291 - val_acc: 0.9918\n",
      "Epoch 38/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0137 - acc: 0.9959 - val_loss: 0.0257 - val_acc: 0.9925\n",
      "Epoch 39/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0149 - acc: 0.9956 - val_loss: 0.0314 - val_acc: 0.9930\n",
      "Epoch 40/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0139 - acc: 0.9954 - val_loss: 0.0291 - val_acc: 0.9929\n",
      "Epoch 41/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0125 - acc: 0.9961 - val_loss: 0.0346 - val_acc: 0.9927\n",
      "Epoch 42/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0137 - acc: 0.9955 - val_loss: 0.0252 - val_acc: 0.9927\n",
      "Epoch 43/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0141 - acc: 0.9957 - val_loss: 0.0324 - val_acc: 0.9936\n",
      "Epoch 44/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0134 - acc: 0.9956 - val_loss: 0.0283 - val_acc: 0.9926\n",
      "Epoch 45/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0123 - acc: 0.9963 - val_loss: 0.0289 - val_acc: 0.9931\n",
      "Epoch 46/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0134 - acc: 0.9957 - val_loss: 0.0352 - val_acc: 0.9917\n",
      "Epoch 47/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0132 - acc: 0.9960 - val_loss: 0.0270 - val_acc: 0.9924\n",
      "Epoch 48/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0120 - acc: 0.9963 - val_loss: 0.0300 - val_acc: 0.9929\n",
      "Epoch 49/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0130 - acc: 0.9958 - val_loss: 0.0315 - val_acc: 0.9938\n",
      "Epoch 50/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0135 - acc: 0.9955 - val_loss: 0.0281 - val_acc: 0.9924\n",
      "Epoch 51/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0110 - acc: 0.9965 - val_loss: 0.0301 - val_acc: 0.9938\n",
      "Epoch 52/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0119 - acc: 0.9962 - val_loss: 0.0338 - val_acc: 0.9930\n",
      "Epoch 53/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0119 - acc: 0.9960 - val_loss: 0.0325 - val_acc: 0.9927\n",
      "Epoch 54/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0123 - acc: 0.9962 - val_loss: 0.0331 - val_acc: 0.9932\n",
      "Epoch 55/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0106 - acc: 0.9969 - val_loss: 0.0329 - val_acc: 0.9936\n",
      "Epoch 56/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0108 - acc: 0.9967 - val_loss: 0.0311 - val_acc: 0.9927\n",
      "Epoch 57/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0112 - acc: 0.9964 - val_loss: 0.0306 - val_acc: 0.9936\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0109 - acc: 0.9966 - val_loss: 0.0279 - val_acc: 0.9928\n",
      "Epoch 59/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0101 - acc: 0.9969 - val_loss: 0.0320 - val_acc: 0.9930\n",
      "Epoch 60/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0116 - acc: 0.9965 - val_loss: 0.0322 - val_acc: 0.9931\n",
      "Epoch 61/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0105 - acc: 0.9968 - val_loss: 0.0302 - val_acc: 0.9935\n",
      "Epoch 62/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0094 - acc: 0.9970 - val_loss: 0.0352 - val_acc: 0.9923\n",
      "Epoch 63/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0104 - acc: 0.9967 - val_loss: 0.0292 - val_acc: 0.9935\n",
      "Epoch 64/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0100 - acc: 0.9969 - val_loss: 0.0333 - val_acc: 0.9928\n",
      "Epoch 65/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0107 - acc: 0.9965 - val_loss: 0.0334 - val_acc: 0.9935\n",
      "Epoch 66/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0112 - acc: 0.9965 - val_loss: 0.0299 - val_acc: 0.9928\n",
      "Epoch 67/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0100 - acc: 0.9969 - val_loss: 0.0306 - val_acc: 0.9937\n",
      "Epoch 68/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0096 - acc: 0.9973 - val_loss: 0.0280 - val_acc: 0.9943\n",
      "Epoch 69/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0092 - acc: 0.9971 - val_loss: 0.0299 - val_acc: 0.9941\n",
      "Epoch 70/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0089 - acc: 0.9973 - val_loss: 0.0351 - val_acc: 0.9926\n",
      "Epoch 71/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0090 - acc: 0.9971 - val_loss: 0.0333 - val_acc: 0.9923\n",
      "Epoch 72/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0087 - acc: 0.9972 - val_loss: 0.0342 - val_acc: 0.9936\n",
      "Epoch 73/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0092 - acc: 0.9970 - val_loss: 0.0301 - val_acc: 0.9929\n",
      "Epoch 74/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0100 - acc: 0.9969 - val_loss: 0.0383 - val_acc: 0.9927\n",
      "Epoch 75/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0087 - acc: 0.9973 - val_loss: 0.0284 - val_acc: 0.9932: 1s \n",
      "Epoch 76/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0096 - acc: 0.9969 - val_loss: 0.0290 - val_acc: 0.9939 - loss: \n",
      "Epoch 77/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0090 - acc: 0.9972 - val_loss: 0.0309 - val_acc: 0.9936\n",
      "Epoch 78/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0094 - acc: 0.9969 - val_loss: 0.0300 - val_acc: 0.9924\n",
      "Epoch 79/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0093 - acc: 0.9970 - val_loss: 0.0331 - val_acc: 0.9933\n",
      "Epoch 80/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0087 - acc: 0.9973 - val_loss: 0.0318 - val_acc: 0.9932\n",
      "Epoch 81/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0083 - acc: 0.9975 - val_loss: 0.0335 - val_acc: 0.9936.0086 - acc:\n",
      "Epoch 82/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0086 - acc: 0.9975 - val_loss: 0.0309 - val_acc: 0.9929\n",
      "Epoch 83/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0089 - acc: 0.9972 - val_loss: 0.0367 - val_acc: 0.9929\n",
      "Epoch 84/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0082 - acc: 0.9974 - val_loss: 0.0358 - val_acc: 0.9932\n",
      "Epoch 85/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0071 - acc: 0.9978 - val_loss: 0.0443 - val_acc: 0.9915\n",
      "Epoch 86/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0072 - acc: 0.9976 - val_loss: 0.0302 - val_acc: 0.9924\n",
      "Epoch 87/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0082 - acc: 0.9973 - val_loss: 0.0357 - val_acc: 0.9938\n",
      "Epoch 88/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0090 - acc: 0.9975 - val_loss: 0.0374 - val_acc: 0.9931\n",
      "Epoch 89/1000\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0079 - acc: 0.9975 - val_loss: 0.0334 - val_acc: 0.9929\n",
      "Epoch 90/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0089 - acc: 0.9973 - val_loss: 0.0297 - val_acc: 0.9935\n",
      "Epoch 91/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0079 - acc: 0.9976 - val_loss: 0.0314 - val_acc: 0.9940\n",
      "Epoch 92/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0091 - acc: 0.9972 - val_loss: 0.0370 - val_acc: 0.9928\n",
      "Epoch 93/1000\n",
      "60000/60000 [==============================] - 8s 126us/step - loss: 0.0084 - acc: 0.9977 - val_loss: 0.0329 - val_acc: 0.9935\n",
      "Epoch 94/1000\n",
      "26112/60000 [============>.................] - ETA: 4s - loss: 0.0066 - acc: 0.9979"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = 9\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(og_test[position])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "\n",
    "to_test = og_test.reshape(og_test.shape[0], 1, img_rows, img_cols, 1)\n",
    "\n",
    "model.predict(to_test[position])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
